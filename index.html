<!-- <!DOCTYPE html> -->
<html lang="en">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>He Chen </title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <!-- Le styles -->
    <link href="./assets_files/bootstrap.min.css" rel="stylesheet">
    <link href="./assets_files/bootstrap-responsive.min.css" rel="stylesheet">
    <link href="./assets_files/yangqing.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
    <script src="assets/js/html5shiv.js"></script>
    <![endif]-->
    <link rel="icon" href="./assets_files/favicon.ico">
	<script type="text/x-mathjax-config">
	MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
	</script>
	<script type="text/javascript"
	src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script>
</head>

<body>


<div class="container span3 hidden-phone">
    <div id="floating_sidebar" class="span3">
        <!-- We use a fancy nav bar if there is enough space -->
        <!--<hr class="hidden-phone">-->
        <br>
        <ul class="nav nav-list bs-docs-sidenav hidden-phone">
            <li><a href="#top">About</a></li>
            <!--<li><a href="#research">Research</a></li>-->
            <li><a href="#publications">Publications</a></li>
            <li><a href="#projects">Projects</a></li>
            <!--<li><a href="#teaching">Teaching</a></li>-->
            <li><a target="_blank"
                   href="https://drive.google.com/file/d/1TjwtkXXW5ULxwbgEfnC7dovav-M8npM8/view?usp=sharing/">CV</a> </a>
            </li>
        </ul>
        <hr class="hidden-phone">
        <div class="text-center hidden-phone">
            <img src="assets_files/abdullahgok.jpg" alt="photo" class="logo-image">
            <br>
			<br>
			<strong>Phd of Electrical and Computer Engineering</strong>
			<br>
			<strong>Boston University</strong>
			<br>            abdullahgok444@gmail.com <br>
            <img src="./assets_files/GitHub-Mark.png" class="icon-adjust"> <a target="_blank"
                                                                              href="https://github.com/AbdGok07/">Github</a>
<br>
        </div>

        <!-- Otherwise, we simply use a flat list of links -->

    </div>
</div>


<div class="container">

    <div class="row">

        <div class="span9">
            <br>
            <h3>
                Abdullah Gok
            </h3>
            <h5>
			
			<br>
            abdullahgok444@gmail.com</a>
            </h5>
            <!-- Do I want to show a pic on the phone screen?
            <div class="text-center visible-phone">
                <img src="assets/img/Yihui.png" alt="photo" width="150px"/>
            </div>
            -->
            <!-- <a class="visible-phone pull-left" href="http://daggerfs.com/index.html#">
                <img class="media-object" src="assets_files/me.jpg" width="96px" style="margin: 0px 10px">
            </a>
			 -->
            <p>
                I'm a PhD candidate at Electrical and Computer Engineering at <a href="https://www.bu.edu/">Boston University</a>
		. I am an interdisciplinary researcher working on optoelectronic device design implementations including numerical and electromagnetic modeling, data analysis and computational analysis.  
				<br /> I am working with Prof. <a href="https://www.bu.edu/eng/profile/roberto-paiella/"> Roberto Paiella </a>.
				
		    I have an interdisciplinary education backgrounds, which is at the intersection of electrical and electronics engineering, computer science,physics, data science and software engineering. 
		    Coding and data analysis is a part of my research.
		   
		    <li>have worked theoretical and numerical design of devices such as LEDs, Lasers, cameras, solar cells, photodetectors using simulation softwares, i.e. Lumerical FDTD, Mode Solver, HFSS
		    COMSOL. 
		    <li>designed and implemented video processing algorithms, hearing aid algorithms, high level calender and socket programs, temperature controller on chip, which required coding in one or two of the programming languages Java, C++,VHDL, C, Assembly. 
		    <li>coded in Pyton and Matlab, and used Linux to map the fourier domain data in space domain. 
		    <li>have been working on omni-directional camera design project, which requires photonic crystal design, and computational imaging operations in 
		    implementation. 
		    <li>have been used nanofabrication techniques, to demonstrate my designs and ideas.
		    <li>programmed in Matlab and Phyton to analyze X-ray data.
	            <li>built optical setups to measure photoluminescence, lasing of designed lasers or emission of leds.
				
            </p>
			
           <!-- <p><strong>
                I am currently applying for full-time jobs. If you're interested, please contact me.
            </strong></p> -->
			
			
			<h3>
            Education
            </h3>
			
			<table>
			<tr>
			<td><strong>PhD in Electrical and Computer Engineering</strong></td>
			<td><strong>:  <a href="https://www.bu.edu/eng/departments/ece/">Boston University</strong></a></td>
			</tr>
				
			<tr>	
			<td><strong>Master of Science in Electrical and Electronics Engineering </strong></td>
			<td><strong>:  <a
                        href="https://w3.bilkent.edu.tr/bilkent/">Bilkent University</strong></a></td>
			</tr>
				
			<tr>
			<td><strong>Bachelor of Science in Electrical and Electronics Engineering</strong></td>
			<td><strong>:  <a href="https://www.bu.edu/eng/departments/ece/"">Bilkent University</strong></a></td>
			</tr>
			<tr>
			
			
				
			
			<tr>
			</table>
			<!--
			
			-->

            
            
            <h3>
            <a name="Research"></a> Research
            </h3>
            <p>
            My current research topics include:
            </p><ul>
            <li> <strong>Next Gen Motion Capture</strong>:  A system to capture more than 1000 unique points on the surfaceof a moving human body. Directly obtain 4D (spatial temporal) data from human motion.
			<li> <strong>Point Cloud</strong>: Point cloud normal estimation, point cloud denoising, point cloud alignment.
            </li><li> <strong>3D Scanning</strong>: Data algning, texture synthesis, mesh reconstruction. Currently focus on registration of depth and feature preserving 
			reconstruction.
			</li><li><a target="_blank" href="https://github.com/MeshFrame/MeshFrame/"><strong>MeshFrame</strong></a> : A lightweight, efficient, header-only mesh processing framework with better efficiency superior to other 
				state-of-the-art libraries. It supports dynamic mesh structure editing,  supports runtime dynamic properties, 
				supports triangle/tetrahedral mesh. It also includes a very fast mesh simplification application.
            </li><li> <strong>Volumetric parameterization</strong>: Given an abitrary volumetric object in form of tetrahedral mesh, and make a bijective PL(Piecewise Linear)
			map from object to a canonical 
			region. I have a parameterization method preserving as much original mesh subdivision structure as possible.
            </li><li> <a target="_blank" href="./FaceReconProject.html"><strong>3D Face Reconstruction</strong></a> ï¼šI have been researching on full face reconstruction from multi-angle RGB-D data and face sequence reconstruction.
			I have developed some cutting-edge application on both PC and mobile platform.
            </li></ul>
            <p></p>


            <!--
             *** Publications ***
            -->
            <h3>
                <a name="publications"></a> Publications
            </h3>
			 <!--
            <p>
                Link to <a target="_blank"
                                           href="https://scholar.google.com/citations?user=z2w3scIAAAAJ&amp;hl=en"
                                           target="_blank">[Google Scholar]</a>
                <a href="projects.html"> [Unpublished Projects]</a>
            </p>
            -->
        <div class="media">
                <a >
                    <img class="media-object" src="./assets_files/Mocap/NewTeaser.jpg" width="800px" height="300px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Capturing Detailed Deformations of Moving Human Bodies 
                     </strong>
						<br />
						<i>ACM Transactions on Graphics 40(4) [Proceedings of SIGGRAPH], 2021  </i>
						<!-- <a
                            href="https://ieeexplore.ieee.org/document/8340177/">[Article Page]</a>,  -->
                        <a
							href="./Projects/MocapCheckerboard/MocapCheckerboard.html">[Project Page]</a>,
						
						<a
							href="https://arxiv.org/pdf/2102.07343.pdf">[PDF]</a>.
                        <br />
                        
                        He Chen, Hyojoon Park, Kutay Macit, Ladislav Kavan
                    </p>
                    <p class="abstract-text">
                        Our method can capture over 1,000 unique points on the human body using only standard cameras and passive lights, without relying on temporal tracking or prior human body models.
                        <!-- We present a new method to capture detailed human motion, sampling more
                        than 1000 unique points on the body. Our method outputs highly accurate
                        4D (spatio-temporal) point coordinates and, crucially, automatically assigns
                        a unique label to each of the points. The locations and unique labels of the
                        points are inferred from individual 2D input images only, without relying on
                        temporal tracking or any human body shape or skeletal kinematics models.
                        Therefore, our captured point trajectories contain all of the details from
                        the input images, including motion due to breathing, muscle contractions
                        and flesh deformation, and are well suited to be used as training data to fit
                        advanced models of the human body and its motion. The key idea behind our
                        system is a new type of motion capture suit which contains a special pattern
                        with checkerboard-like corners and two-letter codes. The images from our
                        multi-camera system are processed by a sequence of neural networks which
                        are trained to localize the corners and recognize the codes, while being
                        robust to suit stretching and self-occlusions of the body. Our system relies
                        only on standard RGB or monochrome sensors and fully passive lighting
                        and the passive suit, making our method easy to replicate, deploy and use
                        Our experiments demonstrate highly accurate captures of a wide variety of
                        human poses, including challenging motions such as yoga, gymnastics, or
                        rolling on the ground. -->
                    </p>
                </div>
            </div> 
        <div class="media">
                <a class="pull-left">
                    <img class="media-object" src="./assets_files/MultiNormal.png" width="200px" height="250px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                             Multi-Normal Estimation via Pair Consistency Voting
                     </strong>
						<br />
						<i>IEEE Transactions on Visualization and Computer Graphics(TVCG)  </i>
						<a
							href="https://ieeexplore.ieee.org/document/8340177/">[Page]</a>, 
						<a
							href="https://www.computer.org/csdl/trans/tg/preprint/08340177.pdf">[PDF].</a>
						<br />
                        Jie Zhang, Junjie Cao (co-first authors), Xiuping Liu, He Chen, Bo Li, Ligang Liu
                    </p>
                    <p class="abstract-text">
                        This paper presents a unified definition for point cloud normal of feature and non-feature points, 
						which allows feature points to possess multiple normals.
						This definition facilitates several succeeding operations, such as feature points extraction and point cloud filtering.
						We also develop a feature preserving normal estimation method which outputs multiple normals per feature point.
						In addition, we introduce an error measure compatible with traditional normal estimators, and present the first benchmark 
						for normal estimation, composed of 152 synthesized data with various features and sampling densities, and 288 real scans 
						with different noise levels.
                    </p>
                </div>
            </div> 
		<div class="media">
                <a class="pull-left">
                    <img class="media-object" src="./assets_files/NeighborhoodShift.png" width="200px" height="250px">
                </a>
				<br />
                <div class="media-body">
					
                    <p class="media-heading">
                        <strong>
                             Normal Estimation via Shifted Neighborhood for point cloud
                     </strong>
					 <br />
						<i>Journal of Computational and Applied Mathematics  </i>
						<a
							href="https://www.sciencedirect.com/science/article/pii/S0377042717301978/">[Page]</a>, 
						<a
							href="https://www.sciencedirect.com/sdfe/pdf/download/read/noindex/pii/S0377042717301978/1-s2.0-S0377042717301978-main.pdf">[PDF].</a>
						<br />
						Junjie Cao, He Chen, Jie Zhang, Yujiao Li, Xiuping Liu, Changqing Zou
                    </p>
                    <p class="abstract-text">
                        We present a fast and quality normal estimator based on neighborhood shift.
						Instead of using the neighborhood centered at the point, we wish to locate a neighborhood containing 
						the point but clear of sharp features, which is usually not centering at the point.
						Two specific neighborhood shift techniques are designed in view of the complex structure of sharp 
						features and the characteristic of raw point clouds.
                    </p>
                </div>
            </div>        
			<div class="media">
                <a class="pull-left">
                    <img class="media-object" src="./assets_files/mesut.png" width="200px" height="250px">
                </a>
				<br />
                <div class="media-body">
					
                    <p class="media-heading">
                        <strong>
                             Online Knapsack Problem Under Concave Functions
                     </strong>
					 <br />
						<i>Frontiers in Algorithmics </i>
						<a
							href="http://www.bookmetrix.com/detail/chapter/46f96b06-8172-489a-8044-4a136e2a689f#downloads/">[Page]</a>, 
						<a
							href="http://www.bookmetrix.com/detail_full/chapter/46f96b06-8172-489a-8044-4a136e2a689f#downloads/">[PDF].</a>
						<br />
						Xin Han, Ning Ma, Kazuhisa Makino, He Chen
                    </p>
                    <p class="abstract-text">
TÃ¼rkÃ§e, diÄŸer pek Ã§ok TÃ¼rk dili ile de paylaÅŸtÄ±ÄŸÄ± sondan eklemeli olmasÄ± ve Ã¼nlÃ¼ uyumu gibi dil bilgisi Ã¶zellikleri ile karakterize edilir. Dil, tÃ¼mce yapÄ±sÄ± aÃ§Ä±sÄ±ndan genellikle Ã¶zne-nesne-yÃ¼klem sÄ±rasÄ±na sahiptir. Almanca, ArapÃ§a gibi dillerin aksine gramatik cinsiyetin (erillik, diÅŸilik, cinsiyet ayrÄ±mÄ±) bulunmadÄ±ÄŸÄ± TÃ¼rkÃ§ede sÃ¶zcÃ¼klerin bir kÄ±smÄ± ArapÃ§a, FarsÃ§a ve FransÄ±zca gibi yabancÄ± dillerden geÃ§medir. AyrÄ±ca Azerice, Gagavuzca ve TÃ¼rkmence gibi diÄŸer OÄŸuz dilleri ile TÃ¼rkÃ§e yÃ¼ksek oranda karÅŸÄ±lÄ±klÄ± anlaÅŸÄ±labilirlik gÃ¶sterir.
                    </p>
                </div>
            </div>   
			<div class="media">
                <a class="pull-left">
                    <img class="media-object" src="./assets_files/meshSaliency.png" width="200px" height="250px">
                </a>
				<br />
                <div class="media-body">
					
                    <p class="media-heading">
                        <strong>
                             Mesh saliency detection via double absorbing Markov chain in feature space
                     </strong>
					 <br />
						<i>The Visual Computer </i>
						<a
							href="https://link.springer.com/article/10.1007/s00371-015-1184-x/">[Page]</a>,
							<a
							href="https://www.researchgate.net/profile/Junjie_Cao/publication/284722787_Mesh_saliency_detection_via_double_absorbing_Markov_chain_in_feature_space/links/5657776208aeafc2aac10256.pdf">[PDF].</a>
						<br />
						Xiuping Liu, Pingping Tao, Junjie Cao, He Chen, Changqing Zou
                    </p>
                    <p class="abstract-text">
                       We propose a mesh saliency detection approach using absorbing Markov chain. Unlike most 
					   of the existing methods based on some center-surround operator, our method employs feature 
					   variance to obtain insignificant regions and considers both background and foreground cues. 
					   
                    </p>
                </div>
            </div> 

            <!--<div class="media">-->
            <!--<a class="pull-left" href="#top">-->
            <!--<img class="media-object" src="./assets_files/decaf-features.png" width="96px" height="96px">-->
            <!--</a>-->
            <!--<div class="media-body">-->
            <!--<p class="media-heading">-->
            <!--<strong>DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition</strong><br>-->
            <!--J Donahue, Y Jia, O Vinyals, J Hoffman, N Zhang, E Tzeng, T Darrell. arXiv preprint.<br>-->
            <!--<a target="_blank" href="http://arxiv.org/abs/1310.1531">[ArXiv Link]</a>-->
            <!--<a target="_blank" href="http://decaf.berkeleyvision.org/">[Live Demo]</a>-->
            <!--<a target="_blank" href="https://github.com/UCB-ICSI-Vision-Group/decaf-release/">[Software]</a>-->
            <!--<a target="_blank" href="http://www.eecs.berkeley.edu/~jiayq/decaf_pretrained/">[Pretrained ImageNet Model]</a>-->
            <!--</p>-->
            <!--<p class="abstract-text">-->
            <!--We evaluate whether features extracted from the activation of a deep convolutional network trained in a fully supervised fashion on a large, fixed set of object recognition tasks can be re-purposed to novel generic tasks. We also released the software and pre-trained network to do large-scale image classification.-->
            <!--</p>-->
            <!--</div>-->
            <!--</div>-->

            <!--
             *** Projects ***
            -->
            <h3>
                <a name="projects"></a> Projects
            </h3>
            Link to my <a target="_blank" href="https://github.com//ankachan/">[github public projects]</a>

            <div class="media">
                <a class="pull-left">
                    <img class="media-object"
                         src="./assets_files/MeshFrame.png"
                         width="200px" height="200px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            MeshFrame: An efficient header-only mesh processing library
                        </strong>
                        <a target="_blank"
                           href="https://github.com/MeshFrame/MeshFrame/">[Link]</a>
                     
                    </p>
                    <p class="abstract-text">
						A open source mesh processing library I developed and maintained as a major contributor, 
						which is a lightweight, efficient, header-only mesh processing framework. Its speed is superior to other 
						state-of-the-art libraries like OpenMesh, MeshLab or CGAL. It supports dynamic 
						mesh structure editing, supports runtime dynamic properties, supports triangle/tetrahedral mesh, 
						with a built-in viewer, and also includes a large number of mesh processing algorithms.
						
                    </p>
                </div>
            </div>

            <div class="media">
                <a class="pull-left">
                   <img class="media-object"
                         src="./assets_files/FaceRecon2.png"
                         width="200px" height="200px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            3DFace:A cross-platform face reconstruction application
                        </strong>
						<a target="_blank"
                           href="./FaceReconProject.html">[Link]</a>
                     
                    </p>
                        
                    </p>
                    <p class="abstract-text">
                        I developed a 3D face reconstruction algorithm using a depth camera. Users can be allowed 
						to automatically capture facial data in the process of rotating face in front of the camera, 
						and use multi-frame alignment technology to merge the geometric and texture data from each 
						angle of the human face, and outputs a more complete human face model in a short peroid of time. Both the mobile and 
						the PC versions of this algorithm have been implemented. On PC, the procedure takes 300ms, 
						on mobile phone the procedure takes 3s.
                    </p>
                </div>
            </div>

            <div class="media">
                <a class="pull-left">
                   <img class="media-object"
                         src="./assets_files/PointCloudAlignment.png"
                         width="200px" height="200px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            3D scanner data processing software
                        </strong>
                        
                    </p>
                    <p class="abstract-text">
                        Developed a software for a 3D scanner, to support point cloud denoising,  point cloud manual editing, 
						point cloud alignment, SLAM global optimization, point cloud reconstruction, feature recovery, mesh
						simplification and other functions, supporting scan data with up to tens of millions of point. In the 
						software development team I am responsible for the implementation of all point cloud processing core algorithms.
                    </p>
                </div>
            </div>  

			<div class="media">
                <a class="pull-left">
                   <img class="media-object"
                         src="./assets_files/MeshSimplification/Before01.png"
                         width="200px" height="200px">
                </a>
				<a class="pull-left">
                   <img class="media-object"
                         src="./assets_files/MeshSimplification/After00.png"
                         width="200px" height="200px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>
                            Mesh Simplification
                        </strong>
                        
                    </p>
                    <p class="abstract-text">
                        This is a mesh simplification algorithm developed as an application of  <a href="https://github.com/MeshFrame/MeshFrame/">MeshFrame</a>.
						The algorithm is based on Quadric Error Metric (QEM). We make use of half-edge collapse method for mesh simplification and modify the 
						QEM to solve the break between different texture coordinates. As far as we know, this is the fastest implementation of QEM based mesh simplification
						algorithm, even faseter than the one  implemented by MeshLab, which is not based on half-edge structure.
                    </p>
                </div>
            </div>        			

            <div class="media">
                <a class="pull-left">
                   <img class="media-object"
                         src="./assets_files/Wing.jpg"
                         width="200px" height="200px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>The Wing Surface Modeling and Gridding </strong>
                        
                    </p>
                    <p class="abstract-text">
                        Generate the wing surface using B-spline parametric surfaces, mastered the method of parametric 
						surfaces for surface subdivision, and learned to use  parametric surface processing software Gmsh.
                    </p>
                </div>
            </div>
			<div class="media">
                <a class="pull-left">
                   <img class="media-object"
                         src="./assets_files/SmartCar.png"
                         width="200px" height="200px">
                </a>
                <div class="media-body">
                    <p class="media-heading">
                        <strong>The Smart Car Competition </strong>
                  
                    </p>
                    <p class="abstract-text">
                        I took part in the smart car competition. In my group, I mainly in charge of the track detecting and 
						controlling algorithm. I learned a lot knowledge about automatic control, embeded system and 
						image processing algorithm.
						
                    </p>
                </div>
            </div>
            <!-- Footer
            ================================================== -->
            <hr>
            <footer class="footer">
                <div class='hidden-phone'>
				 <h3 class="text-center"><a name="wall"></a><strong>Works</strong></h3>
                <!--<h3 class="text-center"><a name="wall"></a><strong>works</strong></h3>-->
                <section id="photos">
                   <img src="./assets_files/MyWork/MultiNormalRender.png"/>
				   <img src="./assets_files/MyWork/Benchmark.png"/>
				   <img src="./assets_files/MyWork/VolumetricParameterization1.png"/>
				   <img src="./assets_files/MyWork/VolumetricParameterization2.png"/>
				   <img src="./assets_files/MyWork/Sphere.png"/>
				   <img src="./assets_files/MyWork/DavidHead1.png"/>
				   <img src="./assets_files/MyWork/DavidHead2.png"/>
				   <img src="./assets_files/MyWork/Cloudprocessing.png"/>
				   <img src="./assets_files/MyWork/Data.png"/>
				   <img src="./assets_files/MyWork/ScannedData.png"/>
				   <img src="./assets_files/MyWork/FeatureNormalComparison.png"/>
    				<img src="./assets_files/MyWork/MeshFrame.png"/>
    				<img src="./assets_files/MyWork/camera1.jpg"/>
    				<img src="./assets_files/MyWork/cellPhone.jpg"/>
    				<img src="./assets_files/MyWork/FaceXB.png"/>
    				
				</section>
                
               
                </div>
                <div class="row">
                    <div class="span12">
                        <p>
                            modified from <a target="_blank" href="http://daggerfs.com/">Â© Yangqing Jia 2013</a>
                        </p>
                    </div>
                </div>

            </footer>
        </div>
    </div>
</div>
</body>
</html>

<!-- Le javascript
================================================== -->
<!-- Placed at the end of the document so the pages load faster -->
<!--
    <script type="text/javascript" src="http://platform.twitter.com/widgets.js"></script>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script src="assets/js/bootstrap-transition.js"></script>
    <script src="assets/js/bootstrap-alert.js"></script>
    <script src="assets/js/bootstrap-modal.js"></script>
    <script src="assets/js/bootstrap-dropdown.js"></script>
    <script src="assets/js/bootstrap-scrollspy.js"></script>
    <script src="assets/js/bootstrap-tab.js"></script>
    <script src="assets/js/bootstrap-tooltip.js"></script>
    <script src="assets/js/bootstrap-popover.js"></script>
    <script src="assets/js/bootstrap-button.js"></script>
    <script src="assets/js/bootstrap-collapse.js"></script>
    <script src="assets/js/bootstrap-carousel.js"></script>
    <script src="assets/js/bootstrap-typeahead.js"></script>
    <script src="assets/js/bootstrap-affix.js"></script>
    <script src="assets/js/holder/holder.js"></script>
    <script src="assets/js/application.js"></script>
-->
